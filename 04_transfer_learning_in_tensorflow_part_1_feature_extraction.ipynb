{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Transfer learning with tensorflow - feature extraction"
      ],
      "metadata": {
        "id": "rZK5UrwJz0eq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Downloading and familiarizing with the data"
      ],
      "metadata": {
        "id": "YzH-0Xwg1p3I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get data (10% of 10 food classes from Food101)\n",
        "import zipfile\n",
        "\n",
        "# Download the data\n",
        "!wget https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_10_percent.zip\n",
        "\n",
        "# Unzip the file\n",
        "zip_ref = zipfile.ZipFile(\"10_food_classes_10_percent.zip\", \"r\")\n",
        "zip_ref.extractall()\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xzSiiuwb2QYq",
        "outputId": "1855317b-42f7-488d-f56f-b782ca0e5fbc"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-01-27 19:15:54--  https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_10_percent.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 172.217.12.27, 142.250.65.123, 172.217.15.251, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|172.217.12.27|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 168546183 (161M) [application/zip]\n",
            "Saving to: ‘10_food_classes_10_percent.zip.1’\n",
            "\n",
            "10_food_classes_10_ 100%[===================>] 160.74M   193MB/s    in 0.8s    \n",
            "\n",
            "2025-01-27 19:15:55 (193 MB/s) - ‘10_food_classes_10_percent.zip.1’ saved [168546183/168546183]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "for dirpath, dirnames, filenames in os.walk(\"10_food_classes_10_percent\"):\n",
        "  print(f\"There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1mCY0thl9uWq",
        "outputId": "86f0a646-2705-4773-c8f1-74d40bb4896b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 2 directories and 0 images in '10_food_classes_10_percent'.\n",
            "There are 10 directories and 0 images in '10_food_classes_10_percent/train'.\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/ramen'.\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/hamburger'.\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/steak'.\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/ice_cream'.\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/grilled_salmon'.\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/chicken_curry'.\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/fried_rice'.\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/chicken_wings'.\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/sushi'.\n",
            "There are 0 directories and 75 images in '10_food_classes_10_percent/train/pizza'.\n",
            "There are 10 directories and 0 images in '10_food_classes_10_percent/test'.\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/ramen'.\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/hamburger'.\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/steak'.\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/ice_cream'.\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/grilled_salmon'.\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/chicken_curry'.\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/fried_rice'.\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/chicken_wings'.\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/sushi'.\n",
            "There are 0 directories and 250 images in '10_food_classes_10_percent/test/pizza'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating data loaders"
      ],
      "metadata": {
        "id": "bAc2uaAl-QyM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup data inputs\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "IMAGE_SHAPE = (224, 224)\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "train_dir = \"10_food_classes_10_percent/train/\"\n",
        "test_dir = \"10_food_classes_10_percent/test/\"\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1/255.)\n",
        "test_datagen = ImageDataGenerator(rescale=1/255.)\n",
        "\n",
        "print(\"Training images:\")\n",
        "train_data_10_percent = train_datagen.flow_from_directory(train_dir,\n",
        "                                               target_size=IMAGE_SHAPE,\n",
        "                                               batch_size=BATCH_SIZE,\n",
        "                                               class_mode=\"categorical\")\n",
        "\n",
        "print(\"Testing images:\")\n",
        "test_data = test_datagen.flow_from_directory(test_dir,\n",
        "                                               target_size=IMAGE_SHAPE,\n",
        "                                               batch_size=BATCH_SIZE,\n",
        "                                               class_mode=\"categorical\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bQH922Dv-8WI",
        "outputId": "39b014df-235a-4d1f-87e7-eab9853bd373"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training images:\n",
            "Found 750 images belonging to 10 classes.\n",
            "Testing images:\n",
            "Found 2500 images belonging to 10 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setting up callbacks"
      ],
      "metadata": {
        "id": "tJq3ptI1AiCG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create tensorboard callback\n",
        "import datetime\n",
        "\n",
        "def create_tensorboard_callback(dir_name, experiment_name):\n",
        "  log_dir = dir_name + \"/\" + experiment_name + \"/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "  tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir)\n",
        "  print(f\"Saving TensorBoard log files to: {log_dir}\")\n",
        "  return tensorboard_callback"
      ],
      "metadata": {
        "id": "PKg2hLLrBLmo"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating models using tensorflow hub"
      ],
      "metadata": {
        "id": "bb0Se2iHELph"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's compare 2 models\n",
        "resnet_url = 'https://tfhub.dev/google/imagenet/resnet_v2_50/feature_vector/4'\n",
        "efficientnet_url = 'https://tfhub.dev/tensorflow/efficientnet/b0/feature-vector/1'"
      ],
      "metadata": {
        "id": "Ny2SOY-wEjzs"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import dependencies\n",
        "# !pip install tensorflow==2.15.0 tensorflow-hub==0.13.0 keras==2.15.0 --force-reinstall"
      ],
      "metadata": {
        "id": "_FwHvegZjKt4"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import dependencies\n",
        "# !pip install tensorflow==2.15.0 tensorflow-hub keras==2.15.0\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from tensorflow.keras import layers"
      ],
      "metadata": {
        "id": "RGO6AsOmJl6S"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's make a create_model() function\n",
        "def create_model(model_url, num_classes=10):\n",
        "  # Download pretrained model\n",
        "  feature_extractor_layer = hub.KerasLayer(model_url,\n",
        "                                          trainable=False,\n",
        "                                          name='feature_extraction_layer',\n",
        "                                          input_shape=IMAGE_SHAPE+(3,))\n",
        "  # Create our own model\n",
        "  # model = tf.keras.Sequential([\n",
        "  #   feature_extractor_layer,\n",
        "  #   layers.Dense(num_classes, activation='softmax', name='output_layer')\n",
        "  # ])\n",
        "  model = tf.keras.Sequential()\n",
        "  model.add(feature_extractor_layer)\n",
        "  model.add(tf.keras.layers.Dense(num_classes, activation=tf.keras.activations.softmax, name='output_layer'))\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "7ZoAMvK_J6RT"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Resnet TensorFlow Hub Feature extraction model"
      ],
      "metadata": {
        "id": "hlK-MxNrLweB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create resnet model\n",
        "resnet_model = create_model(resnet_url, num_classes=train_data_10_percent.num_classes)"
      ],
      "metadata": {
        "id": "me04AZkIL6nY"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resnet_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2fpzz06X4DBV",
        "outputId": "b4a1f2b2-c48b-471e-b6ae-6f15df9be353"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " feature_extraction_layer (  (None, 2048)              23564800  \n",
            " KerasLayer)                                                     \n",
            "                                                                 \n",
            " output_layer (Dense)        (None, 10)                20490     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 23585290 (89.97 MB)\n",
            "Trainable params: 20490 (80.04 KB)\n",
            "Non-trainable params: 23564800 (89.89 MB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile model\n",
        "resnet_model.compile(loss='categorical_crossentropy',\n",
        "                     optimizer=tf.keras.optimizers.Adam(),\n",
        "                     metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "5jOL13AJ5J_G"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model\n",
        "# resnet_history = resnet_model.fit(train_data_10_percent,\n",
        "#                                    epochs=5,\n",
        "#                                    steps_per_epoch=len(train_data_10_percent),\n",
        "#                                   validation_data=test_data,\n",
        "#                                   validation_steps=len(test_data),\n",
        "#                                   callbacks=[create_tensorboard_callback(dir_name='tensorflow_hub',\n",
        "#                                                                          experiment_name='resnet')])"
      ],
      "metadata": {
        "id": "xhR1n8Bg5kcN"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_loss_curves(history):\n",
        "  \"\"\"\n",
        "  Returns separate loss curves for training and validation metrics.\n",
        "  \"\"\"\n",
        "  loss = history.history['loss']\n",
        "  val_loss = history.history['val_loss']\n",
        "\n",
        "  accuracy = history.history['accuracy']\n",
        "  val_accuracy = history.history['val_accuracy']\n",
        "  epochs = range(len(history.history['loss']))\n",
        "\n",
        "  #\n",
        "  plt.plot(epochs, loss, label='training_loss')\n",
        "  plt.plot(epochs, val_loss, label='val_loss')\n",
        "  plt.title('Loss')\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.legend()\n",
        "  plt.figure()\n",
        "\n",
        "  #\n",
        "  plt.plot(epochs, accuracy, label='training_accuracy')\n",
        "  plt.plot(epochs, val_accuracy, label='val_accuracy')\n",
        "  plt.title('Accuracy')\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.legend();\n"
      ],
      "metadata": {
        "id": "eU1a-Eo96Wyv"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot_loss_curves(resnet_history);"
      ],
      "metadata": {
        "id": "nB7MxiW9-kEg"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create and test and EfficientNerB0 model"
      ],
      "metadata": {
        "id": "k-mzxlaA-mH3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "efficient_model = create_model(model_url=efficientnet_url, num_classes=train_data_10_percent.num_classes)\n",
        "\n",
        "efficient_model.compile(loss='categorical_crossentropy',\n",
        "                        optimizer=tf.keras.optimizers.Adam(),\n",
        "                        metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "dtijef4y_rt4"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# efficient_history = efficient_model.fit(train_data_10_percent,\n",
        "#                                        epochs=5,\n",
        "#                                        steps_per_epoch=len(train_data_10_percent),\n",
        "#                                        validation_data=test_data,\n",
        "#                                        validation_steps=len(test_data),\n",
        "#                                        callbacks=[create_tensorboard_callback(dir_name='tensorflow_hub',\n",
        "#                                                                               experiment_name='efficientnet')])"
      ],
      "metadata": {
        "id": "3uQAd7AqAyyz"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_loss_curves(efficient_history);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 148
        },
        "id": "3k6NQQP6BTFp",
        "outputId": "02bb753a-38b0-47b5-d7f1-031ed2c0e425"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'efficient_history' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-25aeb83ba56f>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplot_loss_curves\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mefficient_history\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'efficient_history' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "efficient_model.layers[0].trainable"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E6JrcTZKGxzD",
        "outputId": "a53a011c-05dd-4c6e-e0fe-84b0c5d8058b"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Upload TesorBoard dev records\n",
        "!tensorboard dev u;load --logdir ./tensorflow_hub/ \\\n",
        "  --name \"efficientnet vs resnet\" \\\n",
        "  --description \"comparing 2 image classification models\" \\\n",
        "  --one_shot"
      ],
      "metadata": {
        "id": "gLwY8F9zhkav"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cNd9BN92j34r"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}